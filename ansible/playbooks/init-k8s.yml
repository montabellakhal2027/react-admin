---
- name: Setup Kubernetes Cluster with Calico CNI
  hosts: k8s-master
  become: yes
  vars:
    pod_network_cidr: "192.168.0.0/16"
    calico_version: "v3.28.0"
    k8s_version: "1.28"
  
  tasks:
    # ==================== Pre-flight Checks ====================
    - name: Ensure system requirements
      block:
        - name: Disable swap
          command: swapoff -a
          
        - name: Remove swap from fstab
          lineinfile:
            path: /etc/fstab
            regexp: '.*swap.*'
            state: absent
            
        - name: Load required kernel modules
          modprobe:
            name: "{{ item }}"
            state: present
          loop:
            - overlay
            - br_netfilter
            
        - name: Set sysctl parameters
          sysctl:
            name: "{{ item.key }}"
            value: "{{ item.value }}"
            state: present
            reload: yes
          loop:
            - { key: 'net.bridge.bridge-nf-call-iptables', value: '1' }
            - { key: 'net.bridge.bridge-nf-call-ip6tables', value: '1' }
            - { key: 'net.ipv4.ip_forward', value: '1' }

    # ==================== Thorough Cleanup ====================
    - name: Complete cleanup of previous installation
      block:
        - name: Reset kubeadm
          command: kubeadm reset -f
          ignore_errors: yes
          
        - name: Stop all Kubernetes services
          systemd:
            name: "{{ item }}"
            state: stopped
            enabled: no
          loop:
            - kubelet
            - containerd
          ignore_errors: yes
          
        - name: Kill remaining Kubernetes processes
          shell: |
            pkill -f kube-apiserver || true
            pkill -f kube-controller || true
            pkill -f kube-scheduler || true
            pkill -f kubelet || true
            pkill -f etcd || true
          ignore_errors: yes
          
        - name: Wait for processes to terminate
          pause:
            seconds: 5
            
        - name: Remove Kubernetes directories
          file:
            path: "{{ item }}"
            state: absent
          loop:
            - /etc/kubernetes
            - /var/lib/etcd
            - /var/lib/kubelet
            - /etc/cni/net.d
            - /root/.kube
            - /var/lib/cni
            - /run/kubernetes
            
        - name: Clean iptables rules
          shell: |
            iptables -F && iptables -t nat -F && iptables -t mangle -F && iptables -X
            ip6tables -F && ip6tables -t nat -F && ip6tables -t mangle -F && ip6tables -X
          ignore_errors: yes
          
        - name: Remove virtual network interfaces
          shell: |
            ip link delete cni0 2>/dev/null || true
            ip link delete flannel.1 2>/dev/null || true
            ip link delete kube-ipvs0 2>/dev/null || true
          ignore_errors: yes
          
        - name: Restart containerd
          systemd:
            name: containerd
            state: restarted
            enabled: yes
            
        - name: Wait for containerd to stabilize
          pause:
            seconds: 5
            
        - name: Start and enable kubelet
          systemd:
            name: kubelet
            state: started
            enabled: yes
            
        - name: Verify ports are free
          wait_for:
            port: "{{ item }}"
            state: stopped
            timeout: 30
          loop:
            - 6443
            - 2379
            - 2380
          ignore_errors: yes

    # ==================== Initialize Kubernetes ====================
    - name: Initialize Kubernetes cluster
      command: >
        kubeadm init
        --pod-network-cidr={{ pod_network_cidr }}
        --apiserver-advertise-address={{ ansible_default_ipv4.address }}
      register: kubeadm_init
      
    - name: Display kubeadm init output
      debug:
        var: kubeadm_init.stdout_lines

    # ==================== Configure kubectl ====================
    - name: Create .kube directory
      file:
        path: /root/.kube
        state: directory
        mode: '0755'
        
    - name: Copy admin.conf to .kube/config
      copy:
        src: /etc/kubernetes/admin.conf
        dest: /root/.kube/config
        remote_src: yes
        owner: root
        group: root
        mode: '0600'

    - name: Wait for Kubernetes API to be ready
      wait_for:
        host: "{{ ansible_default_ipv4.address }}"
        port: 6443
        delay: 5
        timeout: 300

    # ==================== Install Calico CNI (Standard Manifest) ====================
    - name: Download Calico manifest
      get_url:
        url: "https://raw.githubusercontent.com/projectcalico/calico/{{ calico_version }}/manifests/calico.yaml"
        dest: /tmp/calico.yaml
        mode: '0644'
        timeout: 120
        
    - name: Check if CIDR modification is needed
      shell: grep -q "192.168.0.0/16" /tmp/calico.yaml
      register: cidr_check
      ignore_errors: yes
      changed_when: false
      
    - name: Apply Calico manifest
      command: kubectl apply -f /tmp/calico.yaml
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: calico_install
      
    - name: Show Calico installation output
      debug:
        var: calico_install.stdout_lines

    # ==================== Wait for Calico Components ====================
    - name: Wait for Calico daemonset to be created
      shell: kubectl get daemonset -n kube-system calico-node --no-headers 2>/dev/null | wc -l
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: calico_ds_check
      until: calico_ds_check.stdout|int > 0
      retries: 30
      delay: 5
      
    - name: Wait for Calico deployment to be created
      shell: kubectl get deployment -n kube-system calico-kube-controllers --no-headers 2>/dev/null | wc -l
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: calico_deploy_check
      until: calico_deploy_check.stdout|int > 0
      retries: 30
      delay: 5

    - name: Display Calico resources
      shell: kubectl get all -n kube-system -l 'k8s-app in (calico-node,calico-kube-controllers)' -o wide
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: calico_resources
      
    - name: Show Calico resources
      debug:
        var: calico_resources.stdout_lines
      
    - name: Wait for Calico node pods to be Running
      shell: |
        READY=$(kubectl get pods -n kube-system -l k8s-app=calico-node -o jsonpath='{.items[*].status.conditions[?(@.type=="Ready")].status}')
        echo "Ready statuses: $READY"
        if echo "$READY" | grep -q "False"; then
          exit 1
        fi
        if [ -z "$READY" ]; then
          exit 1
        fi
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: calico_node_ready
      until: calico_node_ready.rc == 0
      retries: 60
      delay: 10
      
    - name: Wait for Calico controllers to be Running
      shell: |
        READY=$(kubectl get pods -n kube-system -l k8s-app=calico-kube-controllers -o jsonpath='{.items[*].status.conditions[?(@.type=="Ready")].status}')
        echo "Ready statuses: $READY"
        if echo "$READY" | grep -q "False"; then
          exit 1
        fi
        if [ -z "$READY" ]; then
          exit 1
        fi
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: calico_controller_ready
      until: calico_controller_ready.rc == 0
      retries: 60
      delay: 10

    # ==================== Wait for CoreDNS ====================
    - name: Wait for CoreDNS to be ready
      shell: |
        READY=$(kubectl get pods -n kube-system -l k8s-app=kube-dns -o jsonpath='{.items[*].status.conditions[?(@.type=="Ready")].status}')
        echo "Ready statuses: $READY"
        if echo "$READY" | grep -q "False"; then
          exit 1
        fi
        if [ -z "$READY" ]; then
          exit 1
        fi
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: coredns_ready
      until: coredns_ready.rc == 0
      retries: 60
      delay: 10
      
    - name: Wait for master node to be Ready
      shell: kubectl get nodes -o jsonpath='{.items[*].status.conditions[?(@.type=="Ready")].status}'
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: node_status
      until: node_status.stdout == "True"
      retries: 60
      delay: 10

    # ==================== Remove Taints (for single-node) ====================
    - name: Remove master taint (for single-node cluster)
      command: kubectl taint nodes --all node-role.kubernetes.io/control-plane-
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      ignore_errors: yes
      when: true  # Set to false if you have worker nodes

    # ==================== Final Status ====================
    - name: Get cluster status
      shell: |
        echo "=========================================="
        echo "           CLUSTER STATUS"
        echo "=========================================="
        echo ""
        echo "=== NODES ==="
        kubectl get nodes -o wide
        echo ""
        echo "=== SYSTEM PODS ==="
        kubectl get pods -n kube-system -o wide
        echo ""
        echo "=== CALICO PODS ==="
        kubectl get pods -n kube-system -l 'k8s-app in (calico-node,calico-kube-controllers)' -o wide
        echo ""
        echo "=== CLUSTER INFO ==="
        kubectl cluster-info
        echo ""
        echo "=========================================="
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: cluster_status
      
    - name: Display final cluster status
      debug:
        var: cluster_status.stdout_lines
        
    - name: Save join command for worker nodes
      shell: kubeadm token create --print-join-command
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: join_command
      
    - name: Display join command
      debug:
        msg: "Worker nodes can join with: {{ join_command.stdout }}"
        
    - name: Success message
      debug:
        msg: 
          - "=========================================="
          - "   Kubernetes cluster setup complete!"
          - "=========================================="
          - "Cluster is ready for use."
          - "All pods are running successfully."
